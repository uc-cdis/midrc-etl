{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "048c3f62",
   "metadata": {},
   "source": [
    "Sequestration algorithm\n",
    "Separate an incoming data batch into open and sequestered using\n",
    "stratified sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90252eb9",
   "metadata": {},
   "source": [
    "Determine which version of python notebook relies on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "627412fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/3.6.1/libexec/bin/python3.11\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1e8c85",
   "metadata": {},
   "source": [
    "Import modules and set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45ab6ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules and set variables\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import date\n",
    "import random\n",
    "import copy\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e711b066",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "513d49ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Discuss with MIDRC: Custom function, .ipynb vs .py file\n",
    "# Matlab has a function named \"groupcounts\". Below is a pythonic recreation:\n",
    "def groupcounts(df, col_name):\n",
    "    df_out = df[col_name].value_counts().reset_index(name='GroupCount')\n",
    "    df1 = df[col_name].value_counts(normalize =True).reset_index(name='Percent')\n",
    "    df_out['Percent'] = df1['Percent']*100\n",
    "    df_out = df_out.sort_values(['index'])\n",
    "    df_out = df_out.rename(columns={'index': col_name}).reset_index(drop=True)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a683c5",
   "metadata": {},
   "source": [
    "Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "63edf650",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Discussion with MIDRC: Promt was removed. File names & paths hard-coded\n",
    "# Read in Data\n",
    "# prompt = \"Copy filepath to input data: \"\n",
    "# filepath = input(prompt)\n",
    "# Example from my computer\n",
    "filepath = \"/Users/alecsteep/Documents/matlab2python/data/testing_set/\"\n",
    "\n",
    "#if len(filepath) == 0:\n",
    "#    filepath = cwd\n",
    "\n",
    "# prompt = 'Input filename: '\n",
    "# filename = input(prompt)\n",
    "# Example from my computer\n",
    "filename = \"sequestration_data_RSNA_20230131.tsv\"\n",
    "#filename = \"sequestration_data_RSNA_20230214.tsv\"\n",
    "\n",
    "# Verify fields read in with correct data type\n",
    "inputfile = filepath + filename\n",
    "# In the matlab script, the data object is named \"data\". We'll maintain that nomenclature as a pandas data.frame\n",
    "data = pd.read_csv(inputfile,sep = '\\t')\n",
    "# Adjust the data types\n",
    "data['submitter_id'] = data['submitter_id'].astype(str)\n",
    "data[\"age_at_index\"] = pd.to_numeric(data[\"age_at_index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2bdacd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates - If warning presents, go to merge batch\n",
    "ptcount = np.unique(data['submitter_id'])\n",
    "if len(ptcount) != len(data.index):\n",
    "    dupes_n = len(data.index)-len(ptcount)\n",
    "    print(\"WARNING: \" + str(dupes_n) + \" duplicate patients in batch \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f87a929",
   "metadata": {},
   "source": [
    "Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d74fe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Data\n",
    "# sex race ethnicity age_at_index covid19_positive site_id modality\n",
    "for i in range(0, len(data.index)):\n",
    "    if data.loc[i,'sex'] == \"\":\n",
    "        data.loc[i,'sex'] = 'Not Reported'\n",
    "    if data.loc[i, 'ethnicity'] == \"\":\n",
    "        data.loc[i, 'ethnicity'] = 'Not Reported'\n",
    "    if data.loc[i, 'race'] == \"\":\n",
    "        data.loc[i, 'race'] = 'Not Reported'\n",
    "    if data.loc[i, 'covid19_positive'] == \"\":\n",
    "        data.loc[i, 'covid19_positive'] = 'Not Reported'\n",
    "    if math.isnan(data.loc[i, 'age_at_index']) or pd.isnull(data.loc[i, 'age_at_index']):\n",
    "        if data.loc[i, 'age_at_index_gt89'] == \"Yes\":\n",
    "            data.loc[i,'age_at_index'] = 890\n",
    "        else:\n",
    "            data.loc[i,'age_at_index'] = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcb6b57",
   "metadata": {},
   "source": [
    "Convert columns to strings (sex, race, ethnicity, covid19_positive, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36e52962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to strings\n",
    "data['sex'] = data['sex'].astype(str)\n",
    "data['race'] = data['race'].astype(str)\n",
    "data['ethnicity'] = data['ethnicity'].astype(str)\n",
    "data['covid19_positive'] = data['covid19_positive'].astype(str)\n",
    "data['dataset'] = data['dataset'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8eddd0",
   "metadata": {},
   "source": [
    "Modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "70c2a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modality\n",
    "M = groupcounts(data, 'modality')\n",
    "\n",
    "# The modality factors are pre-defined by original author\n",
    "modalityNames = [\"CR\",\"CT\",\"DX\",\"MR\"]\n",
    "\n",
    "# One hot encode modality column with booleans\n",
    "for mn in modalityNames:\n",
    "    data[mn] = data.modality.str.contains(mn).astype('uint8')\n",
    "\n",
    "ModalityCount = [sum(data['CR']), sum(data['CT']), sum(data['DX']), sum(data['MR'])]\n",
    "    \n",
    "M1 = pd.DataFrame({\n",
    "    'modalityNames':modalityNames,\n",
    "    'ModalityCount':ModalityCount\n",
    "}).sort_values(['ModalityCount'], ascending=[False])\n",
    "modalityNames = M1.modalityNames.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0e5e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Discuss with MIDRC: Natalie's code incorporates batch, this code does not, missing file\n",
    "# Pre-assign dataset and compare with previous batches\n",
    "FinalTable = copy.copy(data)\n",
    "FinalTable['batch'] = \"Undefined\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b2c034",
   "metadata": {},
   "source": [
    "Separate age into CDC groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6565f8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Discuss with MIDRC: Location of known bug\n",
    "# Separate age into CDC groups\n",
    "# CDC COVID data uses two sets of age groups: \n",
    "# (1) age-groups consistent with those used across CDC COVID-19 surveillance pages\n",
    "# (2) age groups that are routinely included in NCHS morality reports\n",
    "# Assume 0-17, 18-29, 30-39, 40-49, 50-64, 65-74, 75-84, 85+\n",
    "# From https://www.cdc.gov/nchs/nvss/vsrr/covid_weekly/index.htm#SexAndAge\n",
    "data['agec'] = 0\n",
    "for i in range(0, len(data)):\n",
    "    if data.loc[i, 'age_at_index'] <= 17:\n",
    "        data.loc[i, 'agec'] = 1\n",
    "    elif data.loc[i, 'age_at_index'] > 17 and data.loc[i, 'age_at_index'] <= 29:\n",
    "        data.loc[i, 'agec'] = 2\n",
    "    elif data.loc[i, 'age_at_index'] > 29 and data.loc[i, 'age_at_index'] <= 39:\n",
    "        data.loc[i, 'agec'] = 3\n",
    "    elif data.loc[i, 'age_at_index'] > 39 and data.loc[i, 'age_at_index'] <= 49:\n",
    "        data.loc[i, 'agec'] = 4\n",
    "    elif data.loc[i, 'age_at_index'] > 49 and data.loc[i, 'age_at_index'] <= 64:\n",
    "        data.loc[i, 'agec'] = 5\n",
    "    elif data.loc[i, 'age_at_index'] > 64 and data.loc[i, 'age_at_index'] <= 74:\n",
    "        data.loc[i, 'agec'] = 6\n",
    "    elif data.loc[i, 'age_at_index'] > 74 and data.loc[i, 'age_at_index'] <= 84:\n",
    "        data.loc[i, 'agec'] = 7\n",
    "    elif data.loc[i, 'age_at_index'] > 84 and data.loc[i, 'age_at_index'] <= 140:\n",
    "        data.loc[i, 'agec'] = 8\n",
    "    elif data.loc[i, 'age_at_index'] == 890:\n",
    "        data.loc[i, 'agec'] = 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ac669b",
   "metadata": {},
   "source": [
    "Grab site information and initialize seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e9a52f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab site information and initialize seed\n",
    "\n",
    "#sites = data['site_id'].value_counts().reset_index(name='GroupCount')\n",
    "#df1 = data['site_id'].value_counts(normalize =True).reset_index(name='Percent')\n",
    "#sites['Percent'] = df1['Percent']*100\n",
    "#sites = sites.rename(columns={'index': 'site_id'})\n",
    "sites = groupcounts(data, 'site_id')\n",
    "\n",
    "datasave = copy.copy(data)\n",
    "\n",
    "# Initialize seed as date of sequestration\n",
    "t = date.today()\n",
    "# Note: This command returns a similar, but slightly different value to the matlab equivalent\n",
    "# For notes on datenum conversion: https://stackoverflow.com/questions/32991934/equivalent-function-of-datenumdatestring-of-matlab-in-python\n",
    "seed = date.toordinal(t)+366\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbd227c",
   "metadata": {},
   "source": [
    "Split for each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "279b59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Discuss with MIDRC: Many nested for loops and conditionals: P(coding error) increases\n",
    "# Split for each site\n",
    "percSeq = 0.2\n",
    "\n",
    "for x in range(0, len(sites)):\n",
    "    data = copy.copy(datasave.loc[datasave['site_id'] == sites.loc[x,'site_id']])\n",
    "    \n",
    "    # Gather stats\n",
    "    A = groupcounts(data,'agec')\n",
    "    S = groupcounts(data,'sex')\n",
    "    R = groupcounts(data,'race')\n",
    "    E = groupcounts(data,'ethnicity')\n",
    "    C = groupcounts(data, 'covid19_positive')\n",
    "    \n",
    "    # Split \n",
    "    # Assumes all unique patients\n",
    "    # Separate on C, A, R, G, E, and modality\n",
    "    open1 = pd.DataFrame([])\n",
    "    seq = pd.DataFrame([])\n",
    "    i = 0\n",
    "    feature_list = ['case_n','age_index', 'race_index','sex_index','eth_index']\n",
    "    count = pd.DataFrame(0, index=np.arange(len(A)*len(S)*len(R)*len(E)*len(C)), columns=feature_list)\n",
    "    # count = zeros(height(C)*height(A)*height(R)*height(S)*height(E),5);\n",
    "    for m in range(0,len(modalityNames)):\n",
    "        modality = modalityNames[m]\n",
    "        # Select all patients with given modality inclusive of multiples\n",
    "        tempm = data.loc[data[modality] == 1]\n",
    "        # Remove these from data such that they are not selected again (unnecessary)\n",
    "        i_drops = data.loc[data[modality] == 1].index\n",
    "        data.drop(labels = i_drops, axis = 0, inplace = True)\n",
    "        for cg in range(0, len(C)):\n",
    "            covid_group = C.loc[cg,'covid19_positive']\n",
    "            tempc = tempm.loc[tempm['covid19_positive'] == covid_group]\n",
    "            for ag in range(-1, len(A)):\n",
    "                if(ag == -1):\n",
    "                    age_group = 0\n",
    "                else:\n",
    "                    age_group = A.loc[ag,'agec']\n",
    "                temp1 = tempc.loc[tempc['agec'] == age_group]\n",
    "                for rg in range(0, len(R)):\n",
    "                    race_group = R.loc[rg,'race']\n",
    "                    temp2 = temp1.loc[temp1['race'] == race_group]\n",
    "                    for sg in range(0, len(S)):\n",
    "                        sex_group = S.loc[sg,'sex']\n",
    "                        temp3 = temp2.loc[temp2['sex'] == sex_group]\n",
    "                        for eg in range(0, len(E)):\n",
    "                            ethnicity_group = E.loc[eg,'ethnicity']\n",
    "                            temp4 = temp3.loc[temp3['ethnicity'] == ethnicity_group]\n",
    "                            count.loc[i,] = [len(temp4),ag,rg,sg,eg]\n",
    "                            #print(i)\n",
    "                            i = i + 1\n",
    "                            if len(temp4) > 0:\n",
    "                                if len(temp4) < 5:\n",
    "                                    # Create a list of uniformly distributed random numbers \n",
    "                                    # [0,1] the length of the number of cases in that strata\n",
    "                                    list = np.random.rand(len(temp4),1)\n",
    "                                    # If rand(n) <=0.2 assign test\n",
    "                                    # If rand(n) >0.2 assign train\n",
    "                                    for n in range(0,len(list)):\n",
    "                                        if list[n] > percSeq:\n",
    "                                            add1 = pd.DataFrame(temp4.loc[temp4.index[n]]).transpose()\n",
    "                                            #add1 = pd.DataFrame(temp4.loc[temp4.index[n]])\n",
    "                                            open1 = pd.concat([open1, add1])\n",
    "                                            #print('part1:' + str(open1.shape))\n",
    "                                        else:\n",
    "                                            add2 = pd.DataFrame(temp4.loc[temp4.index[n]]).transpose()\n",
    "                                            #add2 = pd.DataFrame(temp4.loc[temp4.index[n]])\n",
    "                                            seq = pd.concat([seq, add2])\n",
    "                                else:\n",
    "                                    rows = len(temp4)\n",
    "                                    # Shuffle the order of cases in this strata and than assign\n",
    "                                    # the first 80% to train and the last 20% to test\n",
    "                                    arr = np.array(range(0, rows))\n",
    "                                    idx = np.random.permutation(arr)\n",
    "                                    add1 = pd.DataFrame(temp4.loc[temp4.index[idx[range(0, round(rows*(1-percSeq)))]]])\n",
    "                                    open1 = pd.concat([open1, add1])\n",
    "                                    add2 = pd.DataFrame(temp4.loc[temp4.index[idx[range(round(rows*(1-percSeq)),len(idx))]]])\n",
    "                                    seq = pd.concat([seq, add2])\n",
    "                                    #print(open1.shape)\n",
    "                                    \n",
    "    \n",
    "    \n",
    "    # Write results in Final Table\n",
    "    for i in range(0, len(open1)):\n",
    "        idx = FinalTable.index[FinalTable['submitter_id'] == open1['submitter_id'].iloc[i]].tolist()\n",
    "        FinalTable.loc[idx, 'dataset'] = \"Open\"\n",
    "        FinalTable.loc[idx, 'batch'] = filename[len(filename)-12:len(filename)-4]\n",
    "\n",
    "    for i in range(0, len(seq)):\n",
    "        idx = FinalTable.index[FinalTable['submitter_id'] == seq['submitter_id'].iloc[i]].tolist()\n",
    "        FinalTable.loc[idx, 'dataset'] = \"Seq\"\n",
    "        FinalTable.loc[idx, 'batch'] = filename[len(filename)-12:len(filename)-4]\n",
    "\n",
    "idx = FinalTable.index[FinalTable['submitter_id'] == \"Unassigned\"].tolist()\n",
    "if len(idx) > 0:\n",
    "    print(\"Warning: \" + str(len(idx)) +\" patients did not fall in sequestration criteria \\n\")\n",
    "    print(\"Assigning to open dataset \\n\")\n",
    "    FinalTable.loc[idx, 'dataset'] = \"Open\"\n",
    "    FinalTable.loc[idx, 'batch'] = filename[len(filename)-12:len(filename)-4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507513aa",
   "metadata": {},
   "source": [
    "Check for duplicate patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f5a44ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Discuss with MIDRC: Bottle neck, searches fer duplicates could be made more efficient\n",
    "# Check for duplicate patients\n",
    "ptcount = pd.unique(FinalTable['submitter_id'])\n",
    "if not len(ptcount) == len(FinalTable):\n",
    "    dupes = len(FinalTable) - len(ptcount)\n",
    "    print(\"WARNING: \"+str(dupes)+\" duplicate patients in batch \\n\")\n",
    "    count = pd.DataFrame(0, index=np.arange(len(FinalTable)), columns=['duped'])\n",
    "    for i in range(0, len(FinalTable)):\n",
    "        for j in range(0, len(FinalTable)):\n",
    "            if FinalTable.loc[i,'submitter_id'] == FinalTable.loc[j,'submitter_id']:\n",
    "                count.loc[i, 'duped'] = count.loc[i, 'duped'] + 1\n",
    "    dupidx = count.index[count['duped'] > 1].tolist()\n",
    "    datadup = FinalTable.loc[dupidx]\n",
    "    datadup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d38d2e0",
   "metadata": {},
   "source": [
    "Write Gen3 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78d8d2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Discussion with MIDRC: Prompt was removed\n",
    "#prompt = \"Copy filepath to output data: \"\n",
    "#filepath = input(prompt)\n",
    "if len(filepath) == 0:\n",
    "    filepath = cwd\n",
    "# Example from my computer\n",
    "# filepath = \"/Users/alecsteep/Documents/matlab2python/data/testing_set/\"\n",
    "filepath = str(filepath)\n",
    "#FinalTable = removevars(FinalTable, 'study_description');\n",
    "#Gen3Table = [FinalTable(:,1:12) FinalTable(:,17)];\n",
    "# Sort the final table\n",
    "FinalTable = FinalTable.sort_values(['submitter_id'], ascending=[True]).reset_index(drop=True)\n",
    "Gen3Table = FinalTable\n",
    "file_name = filepath + \"Gen3_Files/\" + \"COMPLETED_\" + filename[0:len(filename)-4] + \".tsv\"\n",
    "Gen3Table.to_csv(file_name, sep='\\t', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a99bc9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count.loc[i, 'duped'] = count.loc[i, 'duped'] + 1\n",
    "#count.loc[i, 'duped']\n",
    "\n",
    "#.reset_index(drop=True)\n",
    "#C = np.unique(FinalTable['submitter_id'])\n",
    "#C\n",
    "#ia = range(0,len(C))\n",
    "#ia\n",
    "input_file = copy.copy(filename)\n",
    "total_count = len(FinalTable)\n",
    "open_count = len(FinalTable[FinalTable['dataset'] == \"Open\"])\n",
    "seq_count = len(FinalTable[FinalTable['dataset'] == \"Seq\"])\n",
    "site_list = np.unique(sites['site_id'])\n",
    "log = pd.DataFrame([t, input_file,seed,total_count,open_count,seq_count,site_list]).transpose()\n",
    "log.columns =[\"t\",\"input_file\",\"seed\",\"total_count\",\"open_count\",\"seq_count\",\"site_list\"]\n",
    "log\n",
    "if not os.path.exists(filepath + \"MIDRC_EXAMPLE_sequestration_log.csv\"):\n",
    "    log.to_csv(filepath + \"MIDRC_EXAMPLE_sequestration_log.tsv\", sep='\\t', encoding='utf-8', index=False)\n",
    "else:\n",
    "    log.to_csv(filepath + \"MIDRC_EXAMPLE_sequestration_log.tsv\", sep='\\t', encoding='utf-8', index=False, mode='a', header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cea5fa",
   "metadata": {},
   "source": [
    "Write entry in seq log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf4ea6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write entry in seq log\n",
    "FinalTable = FinalTable[FinalTable['batch'] == filename[len(filename)-12:len(filename)-4]]\n",
    "FinalTable[FinalTable['submitter_id'] == np.unique(FinalTable['submitter_id'])].reset_index(drop=True)\n",
    "C = np.unique(FinalTable['submitter_id'])\n",
    "ia = range(0,len(C))\n",
    "\n",
    "# date, filename, seed, sites, total count, open count, seq count\n",
    "input_file = copy.copy(filename)\n",
    "total_count = len(FinalTable)\n",
    "open_count = len(FinalTable[FinalTable['dataset'] == \"Open\"])\n",
    "seq_count = len(FinalTable[FinalTable['dataset'] == \"Seq\"])\n",
    "site_list = np.unique(sites['site_id'])\n",
    "log = pd.DataFrame([t, input_file,seed,total_count,open_count,seq_count,site_list]).transpose()\n",
    "log.columns =[\"t\",\"input_file\",\"seed\",\"total_count\",\"open_count\",\"seq_count\",\"site_list\"]\n",
    "log\n",
    "if not os.path.exists(filepath + \"MIDRC_EXAMPLE_sequestration_log.csv\"):\n",
    "    log.to_csv(filepath + \"MIDRC_EXAMPLE_sequestration_log.tsv\", sep='\\t', encoding='utf-8', index=False)\n",
    "else:\n",
    "    log.to_csv(filepath + \"MIDRC_EXAMPLE_sequestration_log.tsv\", sep='\\t', encoding='utf-8', index=False, mode='a', header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895c1fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This last bit of code is matlab. Original author notes in video that this code is not necessary and it's \n",
    "# function is to create pi charts for visual checks. This code was not converted to python, it was inferred that\n",
    "# is was not desired for translation. However, code may be translated upon request.\n",
    "\n",
    "\n",
    "#%% Write results to data evaluation sheet\n",
    "#% One per batch\n",
    "\n",
    "#% Filename \"MIDRC_sequestration_data_<recieved date>_<site_id>_<date ran>.xlsx\"\n",
    "#evalsheet = filepath + \"Eval_\" + filename(1:end-5) +\".xlsx\";\n",
    "#copyfile(filepath + \"/MIDRC_sequestration_site-id_MM_DD_YY.xlsx\", evalsheet)\n",
    "    \n",
    "#InputTable = FinalTable;\n",
    "#[A,R,S,E,C,M] = CountSeqCategories(InputTable);\n",
    "#writematrix(A,evalsheet,'Sheet',2,'Range','B5:B13')\n",
    "#writematrix(R,evalsheet,'Sheet',2,'Range','B15:B21')\n",
    "#writematrix(S,evalsheet,'Sheet',2,'Range','B23:B26')\n",
    "#writematrix(E,evalsheet,'Sheet',2,'Range','B28:B30')\n",
    "#writematrix(C,evalsheet,'Sheet',2,'Range','B32:B34')\n",
    "#writematrix(M,evalsheet,'Sheet',2,'Range','B36:B39')\n",
    "    \n",
    "#open = InputTable(InputTable.dataset == \"Open\",:);\n",
    "#[A,R,S,E,C,M] = CountSeqCategories(open);\n",
    "#writematrix(A,evalsheet,'Sheet',2,'Range','F5:F13')\n",
    "#writematrix(R,evalsheet,'Sheet',2,'Range','F15:F21')\n",
    "#writematrix(S,evalsheet,'Sheet',2,'Range','F23:F26')\n",
    "#writematrix(E,evalsheet,'Sheet',2,'Range','F28:F30')\n",
    "#writematrix(C,evalsheet,'Sheet',2,'Range','F32:F34')\n",
    "#writematrix(M,evalsheet,'Sheet',2,'Range','F36:F39')\n",
    "    \n",
    "#seq = InputTable(InputTable.dataset == \"Seq\",:);\n",
    "#[A,R,S,E,C,M] = CountSeqCategories(seq);\n",
    "#writematrix(A,evalsheet,'Sheet',2,'Range','J5:J13')\n",
    "#writematrix(R,evalsheet,'Sheet',2,'Range','J15:J21')\n",
    "#writematrix(S,evalsheet,'Sheet',2,'Range','J23:J26')\n",
    "#writematrix(E,evalsheet,'Sheet',2,'Range','J28:J30')\n",
    "#writematrix(C,evalsheet,'Sheet',2,'Range','J32:J34')\n",
    "#writematrix(M,evalsheet,'Sheet',2,'Range','J36:J39')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
