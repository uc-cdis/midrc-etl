{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30efa373",
   "metadata": {},
   "source": [
    "# Quality Check of Data in Staging and ValidateStaging Environment prior to Monthly Release\n",
    "---\n",
    "by Johnbright Anyaibe, M.S\n",
    "\n",
    "Scientific Support Analyst at the Center for Translational Data Science at University of Chicago\n",
    "\n",
    "April 2023\n",
    "\n",
    "---\n",
    "\n",
    "The purpose of the notebook is to do some basic quality checks of batches of data received from data contributors in MIDRC prior to monthly release. This is a post-ingestion check.\n",
    "Thi is a quality chek of the data in both [MIDRC-Staging](https://staging.midrc.org/dd) and [MIDRC-ValidateStaging](https://validatestaging.midrc.org/dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaefa70",
   "metadata": {},
   "source": [
    "Import necessary libraries such as pandas, numpy, os, and the gen3 SDK for accessing the MIDRC API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c18724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import gen3\n",
    "from gen3.submission import Gen3Submission\n",
    "from gen3.auth import Gen3Auth\n",
    "from gen3.index import Gen3Index\n",
    "from gen3.query import Gen3Query\n",
    "git_dir='/Users/johnbrightanyaaibe/Documents/GitHub'\n",
    "sdk_dir='/cgmeyer/gen3sdk-python'\n",
    "sys.path.insert(1, '{}{}'.format(git_dir,sdk_dir))\n",
    "from expansion.expansion import Gen3Expansion\n",
    "%run /Users/johnbrightanyaaibe/Documents/GitHub/cgmeyer/gen3sdk-python/expansion/expansion.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3459fb76",
   "metadata": {},
   "source": [
    "Setting up authentication credentials for the MIDRC API and three different environments (API, validatestaging, and staging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = 'https://data.midrc.org'\n",
    "cred = '/Users/johnbrightanyaaibe/Downloads/midrc-credentials.json'\n",
    "auth = Gen3Auth(api, refresh_file=cred)\n",
    "sub = Gen3Submission(api, auth)\n",
    "query = Gen3Query(auth)\n",
    "index = Gen3Index(auth)\n",
    "exp = Gen3Expansion(api,auth,sub)\n",
    "exp.get_project_ids()\n",
    "########################\n",
    "vapi = 'https://validatestaging.midrc.org'\n",
    "vcred = '/Users/johnbrightanyaaibe/Downloads/midrc-validatestaging-credentials.json'\n",
    "vauth = Gen3Auth(vapi, refresh_file=vcred)\n",
    "vsub = Gen3Submission(vapi, vauth)\n",
    "vquery = Gen3Query(vauth)\n",
    "vexp = Gen3Expansion(vapi,vauth,vsub)\n",
    "vexp.get_project_ids()\n",
    "########################\n",
    "sapi = 'https://staging.midrc.org'\n",
    "scred = '/Users/johnbrightanyaaibe/Downloads/midrc-staging-credentials.json'\n",
    "sauth = Gen3Auth(sapi, refresh_file=scred)\n",
    "ssub = Gen3Submission(sapi, sauth)\n",
    "squery = Gen3Query(sauth)\n",
    "sexp = Gen3Expansion(sapi,sauth,ssub)\n",
    "sexp.get_project_ids()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e11fcc",
   "metadata": {},
   "source": [
    "Defining variables for the batch, user, and node that will be used in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c23075",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = \"\"\n",
    "user = \"\"\n",
    "node = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedeb5c0",
   "metadata": {},
   "source": [
    "Reading in metadata from TSV files that are downloaded to the user's local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b062ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsync -rP utilityvm.midrc.csoc:/home/ubuntu/download/RSNA_20230117/ /Users/johnbrightanyaaibe/Documents/Notes/MIDRC/submission_tsvs/RSNA_20230117\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a54d072",
   "metadata": {},
   "source": [
    "Following code reads TSV files in a specific folder and outputs the length of each file. \n",
    "\n",
    "- It first defines the `folder_path` variable with the path to the folder where the TSV files are located, and the `file_suffix` variable with the suffix of the TSV files to be read.\n",
    "- It then loops through all the files in the `folder_path` directory using `os.listdir()`.\n",
    "- For each file in the directory, it checks if the file name ends with the specified `file_suffix` using the `.endswith()` method.\n",
    "- If the file name ends with the specified suffix, it creates a full path to the file using `os.path.join()` and reads the file into a Pandas DataFrame using `pd.read_csv()`. \n",
    "- Finally, it prints the length of the DataFrame using `len(df)` along with the name of the file.\n",
    "\n",
    "Overall, this code is useful for quickly checking the size of multiple TSV files in a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b6210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/Users/johnbrightanyaaibe/Documents/Notes/MIDRC/submission_tsvs/RSNA_20230117\"\n",
    "file_suffix = \"RSNA_20230117.tsv\"\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(file_suffix):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path, sep=\"\\t\")\n",
    "        print(f\"Length of {filename}: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb65d140",
   "metadata": {},
   "source": [
    "Cross-checking the metadata with what has been submitted and validating the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c04fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the given metadata\n",
    "filename = \"/Users/johnbrightanyaaibe/Documents/Notes/MIDRC/submission_tsvs/RSNA_20230117/originals/case_RSNA_20230117.tsv\"\n",
    "batch_df = pd.read_csv(filename,sep='\\t',header=0,dtype=str)\n",
    "len(list(set(batch_df.submitter_id)))\n",
    "batch_ids = list(set(batch_df.submitter_id))\n",
    "\n",
    "# crosscheck the given metadata with what's been submitted\n",
    "sexp.get_node_tsvs(node=node,overwrite=False,remove_empty=True)\n",
    "node_filename= \"path to exported node tsv\"\n",
    "node_df = pd.read_csv(node_filename,sep='\\t',header=0,dtype=str)\n",
    "\n",
    "hdf = node_df.loc[node_df.submitter_ids.isin(batch_ids)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7db0d4c",
   "metadata": {},
   "source": [
    "If there any removals, the following code can be used in tandem with a manifest of the removed records to get a count of the removed records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34e92fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = \"/Users/johnbrightanyaaibe/Documents/Notes/MIDRC/submission_tsvs/RSNA_20230117/case_RSNA_20230117.tsv\"\n",
    "file2 = \"/Users/johnbrightanyaaibe/Documents/Notes/MIDRC/submission_tsvs/RSNA_20230117/remove4grandchallenge2_image_manifest_RSNA_20230117.tsv\"\n",
    "\n",
    "df1 = pd.read_csv(file1, delimiter='\\t')\n",
    "df2 = pd.read_csv(file2, delimiter='\\t')\n",
    "\n",
    "# extract the case_ids column from both dataframes\n",
    "case_ids1 = set(df1['case_ids'])\n",
    "case_ids2 = set(df2['case_ids'])\n",
    "\n",
    "# count the number of common values between the two columns\n",
    "common_values_count = len(case_ids1.intersection(case_ids2))\n",
    "\n",
    "print(f\"There are {common_values_count} common values in the case_ids column of the two files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d38e69",
   "metadata": {},
   "source": [
    "The following code loops through all the files in a repositiory and see how many records are in common with the manifest of the removed records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1521be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize an empty dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# loop through all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".tsv\"):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        df1 = pd.read_csv(filepath, delimiter='\\t')\n",
    "        if 'case_ids' in df1.columns:\n",
    "            case_ids1 = set(df1['case_ids'])\n",
    "            common_values_count = len(case_ids1.intersection(case_ids2))\n",
    "            results[filename] = common_values_count\n",
    "\n",
    "# print the results\n",
    "for filename, count in results.items():\n",
    "    print(f\"{filename}: {count} common values with manifest of removed records.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
